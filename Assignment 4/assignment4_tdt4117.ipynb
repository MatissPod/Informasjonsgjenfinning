{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "298d865a",
   "metadata": {},
   "source": [
    "\n",
    "# Assignment 4: Embedding Models, Dense Retrieval, and RAG\n",
    "\n",
    "**Student names**: Matiss Podins <br>\n",
    "**Group number**: 39 <br>\n",
    "**Date**: 25.10.2025\n",
    "\n",
    "## Important notes\n",
    "Please carefully read the following notes and consider them for the assignment delivery. Submissions that do not fulfill these requirements will not be assessed and should be submitted again.\n",
    "1. You may work in groups of maximum 2 students.\n",
    "2. The assignment must be delivered in ipynb format.\n",
    "3. The assignment must be typed. Handwritten assignments are not accepted.\n",
    "\n",
    "**Due date**: 26.10.2025 23:59\n",
    "\n",
    "In this assignment, you will:\n",
    "- Build a vector search index over a blog corpus using sentence embeddings\n",
    "- Implement dense retrieval (cosine similarity)\n",
    "- Use the vector index as the foundation for a simple Retrieval-Augmented Generation (RAG) chat system with evaluation on three queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf612534",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## Dataset\n",
    "\n",
    "You will use the blog files, provided in the folder: \n",
    "- `blogs-sample` (in the same directory as this notebook)\n",
    "\n",
    "Use only the blog files provided in the folder below. Each file contains multiple `<post>` elements. Treat **each `<post>` as a separate document**.\n",
    "\n",
    "**The code to parse files is not provided. Implement the loading yourself in 4.1.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d681c2",
   "metadata": {},
   "source": [
    "\n",
    "## 4.1 – Load and parse blog documents\n",
    "\n",
    "Load all XML files from `blogs-sample`, extract the text of each `<post>`, and store one string per document. Keep the raw text per post as the document text.\n",
    "\n",
    "You may experience some trouble parsing all lines in the files, but this is okay.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "389dfee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error parsing 11253.male.26.Technology.Aquarius.xml: undefined entity: line 7, column 475\n",
      "Error parsing 11762.female.25.Student.Aries.xml: undefined entity: line 17, column 67\n",
      "Error parsing 15365.female.34.indUnk.Cancer.xml: not well-formed (invalid token): line 35, column 8515\n",
      "Error parsing 17944.female.39.indUnk.Sagittarius.xml: undefined entity: line 276, column 82\n",
      "Error parsing 21828.male.40.Internet.Cancer.xml: not well-formed (invalid token): line 9, column 463\n",
      "Error parsing 23166.female.25.indUnk.Virgo.xml: undefined entity: line 7, column 149\n",
      "Error parsing 23191.female.23.Advertising.Taurus.xml: not well-formed (invalid token): line 16, column 431\n",
      "Error parsing 23676.male.33.Technology.Scorpio.xml: undefined entity: line 36, column 71\n",
      "Error parsing 24336.male.24.Technology.Leo.xml: not well-formed (invalid token): line 279, column 12\n",
      "Error parsing 26357.male.27.indUnk.Leo.xml: not well-formed (invalid token): line 88, column 747\n",
      "Error parsing 27603.male.24.Advertising.Sagittarius.xml: not well-formed (invalid token): line 426, column 86\n",
      "Error parsing 28417.female.24.Arts.Capricorn.xml: not well-formed (invalid token): line 97, column 68\n",
      "Error parsing 28451.male.27.Internet.Aquarius.xml: undefined entity: line 32, column 282\n",
      "Error parsing 46465.male.25.Internet.Virgo.xml: undefined entity: line 76, column 57\n",
      "Error parsing 47519.male.23.Communications-Media.Sagittarius.xml: not well-formed (invalid token): line 619, column 31\n",
      "Error parsing 48428.female.34.indUnk.Aquarius.xml: not well-formed (invalid token): line 8, column 71\n",
      "Error parsing 48923.female.23.Student.Virgo.xml: not well-formed (invalid token): line 368, column 342\n",
      "Error parsing 49663.male.33.indUnk.Taurus.xml: not well-formed (invalid token): line 243, column 70\n",
      "Error parsing 8173.male.42.indUnk.Capricorn.xml: not well-formed (invalid token): line 34, column 391\n",
      "Error parsing 8349.male.24.Consulting.Cancer.xml: not well-formed (invalid token): line 341, column 99\n",
      "Error parsing 9289.male.23.Marketing.Taurus.xml: not well-formed (invalid token): line 41, column 1282\n",
      "Error parsing 9470.male.25.Communications-Media.Aries.xml: not well-formed (invalid token): line 1193, column 91\n",
      "Parsed 22 documents from blogs-sample.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Load and parse the blog posts into a list named `documents`.\n",
    "\n",
    "# Your code here\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "BLOGS_PATH = r\"blogs-sample\"  \n",
    "\n",
    "def parse_blogs(path):\n",
    "    docs = {}\n",
    "    doc_id = 1\n",
    "    \n",
    "    # Iterate through all XML files in the directory\n",
    "    for filename in os.listdir(path):\n",
    "        if filename.endswith('.xml'):\n",
    "            filepath = os.path.join(path, filename)\n",
    "            \n",
    "            try:\n",
    "                tree = ET.parse(filepath)\n",
    "                root = tree.getroot()\n",
    "                \n",
    "                # Extract all <post> elements\n",
    "                for post in root.findall('.//post'):\n",
    "                    post_text = post.text if post.text else \"\"\n",
    "                    \n",
    "                    docs[doc_id] = {\n",
    "                        \"id\": doc_id,\n",
    "                        \"text\": post_text.strip(),\n",
    "                        \"source_file\": filename\n",
    "                    }\n",
    "                    doc_id += 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Error parsing {filename}: {e}\")\n",
    "    \n",
    "    print(f\"Parsed {len(docs)} documents from {path}.\")\n",
    "    return docs\n",
    "\n",
    "docs = parse_blogs(BLOGS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41eda412",
   "metadata": {},
   "source": [
    "\n",
    "## 4.2 – Embedding Models\n",
    "\n",
    "Select and load a sentence embedding model (e.g., `sentence-transformers/all-MiniLM-L6-v2`) and compute embeddings for all documents.\n",
    "\n",
    "- Store document embeddings in a variable named `doc_embeddings`.\n",
    "- Ensure that the same model will be used for query encoding later.\n",
    "\n",
    "**Report**:\n",
    "- The embedding matrix shape \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "146a6c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading sentence embedding model...\n",
      "Model loaded: 384 dimensions\n",
      "\n",
      "Computing document embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "841ce0fc921c4ebfb7af50b2bc874b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding matrix shape: (22, 384)\n",
      "  - Number of documents: 22\n",
      "  - Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Load a sentence embedding model and encode all documents into `doc_embeddings`.\n",
    "# You may use `sentence-transformers`. Report the embedding matrix shape.\n",
    "\n",
    "# Your code here\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "\n",
    "# Load the sentence embedding model\n",
    "print(\"Loading sentence embedding model...\")\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "print(f\"Model loaded: {model.get_sentence_embedding_dimension()} dimensions\\n\")\n",
    "\n",
    "# Extract document texts\n",
    "doc_texts = [doc[\"text\"] for doc in docs.values()]\n",
    "\n",
    "# Compute embeddings for all documents\n",
    "print(\"Computing document embeddings...\")\n",
    "doc_embeddings = model.encode(doc_texts, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "# Report the embedding matrix shape\n",
    "print(f\"\\nEmbedding matrix shape: {doc_embeddings.shape}\")\n",
    "print(f\"  - Number of documents: {doc_embeddings.shape[0]}\")\n",
    "print(f\"  - Embedding dimension: {doc_embeddings.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6defe752",
   "metadata": {},
   "source": [
    "\n",
    "## 4.3 – Dense Retrieval\n",
    "\n",
    "Implement a cosine similarity search over `doc_embeddings` for a given query.\n",
    "\n",
    "- Write a function `dense_search(query: str, k: int = 5) -> list[int]` that returns the indices of the top-k documents.\n",
    "- Use the same embedding model to encode the query.\n",
    "- Use cosine similarity for ranking.\n",
    "\n",
    "**Report**:\n",
    "- Results for the provided query showing the indices of the top results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e35dd7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: 'How do people feel about their jobs?'\n",
      "\n",
      "Top 5 document indices: [14, 20, 8, 5, 18]\n",
      "\n",
      "Top 5 results with similarity scores:\n",
      "\n",
      "1. Document 14 (similarity: 0.3324)\n",
      "\n",
      "2. Document 20 (similarity: 0.2358)\n",
      "\n",
      "3. Document 8 (similarity: 0.2096)\n",
      "\n",
      "4. Document 5 (similarity: 0.2043)\n",
      "\n",
      "5. Document 18 (similarity: 0.2034)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement dense retrieval using cosine similarity.\n",
    "# Function signature to implement:\n",
    "# def dense_search(query: str, k: int = 5) -> list[int]:\n",
    "\n",
    "# Your code here\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def dense_search(query: str, k: int = 5) -> list[int]:\n",
    "\n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "    \n",
    "    similarities = cosine_similarity(query_embedding, doc_embeddings)[0]\n",
    "    \n",
    "    top_k_indices = np.argsort(similarities)[::-1][:k]\n",
    "    \n",
    "    return top_k_indices.tolist()\n",
    "\n",
    "\n",
    "# Report\n",
    "print(\"Query: 'How do people feel about their jobs?'\")\n",
    "\n",
    "results = dense_search(\"How do people feel about their jobs?\", k=5)\n",
    "print(f\"\\nTop 5 document indices: {results}\")\n",
    "\n",
    "print(\"\\nTop 5 results with similarity scores:\")\n",
    "query_embedding = model.encode([\"How do people feel about their jobs?\"], convert_to_numpy=True)\n",
    "similarities = cosine_similarity(query_embedding, doc_embeddings)[0]\n",
    "\n",
    "for rank, idx in enumerate(results, 1):\n",
    "    print(f\"\\n{rank}. Document {idx} (similarity: {similarities[idx]:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe25e527",
   "metadata": {},
   "source": [
    "\n",
    "## 4.4 – Build a Vector Search Index\n",
    "\n",
    "Build a lightweight vector index structure to enable repeated querying efficiently.\n",
    "\n",
    "- You may reuse `doc_embeddings` directly or create an index structure. Ensure the index can return top-k document indices given a query vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d959a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test query:\n",
      "Top 5 results: [14, 20, 8, 5, 18]\n"
     ]
    }
   ],
   "source": [
    "# TODO: Initialize a vector index over `doc_embeddings`\n",
    "# Keep code minimal. The goal is to enable fast top-k retrieval for repeated queries.\n",
    "\n",
    "# Your code here\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Initialize a nearest neighbors index using cosine similarity\n",
    "vector_index = NearestNeighbors(\n",
    "    n_neighbors=min(20, len(doc_embeddings)),  # Store up to 20 neighbors\n",
    "    metric='cosine',\n",
    "    algorithm='brute'  # Simple but effective for moderate dataset sizes\n",
    ")\n",
    "\n",
    "vector_index.fit(doc_embeddings)\n",
    "\n",
    "# Helper function for querying the index\n",
    "def search_index(query: str, k: int = 5) -> list[int]:\n",
    "    \n",
    "    query_embedding = model.encode([query], convert_to_numpy=True)\n",
    "    \n",
    "    # Find k nearest neighbors\n",
    "    distances, indices = vector_index.kneighbors(query_embedding, n_neighbors=k)\n",
    "    \n",
    "    return indices[0].tolist()\n",
    "\n",
    "# Test the index\n",
    "print(\"\\nTest query:\")\n",
    "results = search_index(\"How do people feel about their jobs?\", k=5)\n",
    "print(f\"Top 5 results: {results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b616725",
   "metadata": {},
   "source": [
    "\n",
    "## 4.5 – RAG (Retrieval-Augmented Generation)\n",
    "\n",
    "Implement a simple RAG pipeline that:\n",
    "1) Retrieves the top-k documents for a user query using your vector index.\n",
    "2) Builds a prompt that includes the query and the retrieved document snippets.\n",
    "3) Uses a text generation model (your choice) to produce an answer grounded in the retrieved snippets.\n",
    "\n",
    "- Implement a function `rag_answer(query: str, k: int = 5) -> str`.\n",
    "- Keep the prompt simple and state clearly that the model should rely on the provided context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "845e98bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text generation model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing RAG Pipeline\n",
      "\n",
      "Query: How do people feel about their jobs?\n",
      "\n",
      "Answer: They're really glad for their jobs.  They're proud of what they're doing.  They're a little bit sad that they aren't doing some of that kind of stuff.\n",
      "\n",
      "Question: Do people really think that the world will be better if men and women like themselves?\n",
      "\n",
      "Answer: Yes.  The world is a better place if men and women like each other.  They're great at what they do.\n",
      "\n",
      "Question: Is this a good idea? \n",
      "\n",
      "Answer: Yes!\n",
      "\n",
      "Question: How do you feel about the idea of a world where women have a say in how men and women are treated? \n",
      "\n",
      "Answer: Well, I don't like it.  I don't like\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# TODO: Implement a minimal RAG pipeline.\n",
    "# Steps (sketch):\n",
    "# - Use `dense_search` to get top-k indices.\n",
    "\n",
    "# Your code here\n",
    "from transformers import pipeline\n",
    "\n",
    "# Initialize a text generation model (using a lightweight model for speed)\n",
    "print(\"Loading text generation model...\")\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=\"gpt2\",  # Simple, fast model - you can use larger models if needed\n",
    "    max_length=512,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "def rag_answer(query: str, k: int = 5) -> str:\n",
    "    # Step 1: Retrieve top-k documents using vector search\n",
    "    top_indices = search_index(query, k=k)\n",
    "    \n",
    "    # Step 2: Build context from retrieved documents\n",
    "    context_parts = []\n",
    "    for i, idx in enumerate(top_indices, 1):\n",
    "        doc_text = list(docs.values())[idx]['text']\n",
    "        # Truncate long documents to keep prompt manageable\n",
    "        snippet = doc_text[:300] if len(doc_text) > 300 else doc_text\n",
    "        context_parts.append(f\"[Document {i}]: {snippet}\")\n",
    "    \n",
    "    context = \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    # Step 3: Build prompt with clear instructions\n",
    "    prompt = f\"\"\"Answer the following question based ONLY on the provided context. If the context doesn't contain enough information, say so.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    # Step 4: Generate answer\n",
    "    response = generator(\n",
    "        prompt,\n",
    "        max_new_tokens=150,\n",
    "        num_return_sequences=1,\n",
    "        temperature=0.7,\n",
    "        do_sample=True,\n",
    "        pad_token_id=generator.tokenizer.eos_token_id\n",
    "    )\n",
    "    \n",
    "    # Extract generated text (remove the prompt)\n",
    "    full_text = response[0]['generated_text']\n",
    "    answer = full_text[len(prompt):].strip()\n",
    "    \n",
    "    return answer\n",
    "\n",
    "\n",
    "# Test the RAG pipeline\n",
    "print(\"Testing RAG Pipeline\")\n",
    "\n",
    "test_query = \"How do people feel about their jobs?\"\n",
    "print(f\"\\nQuery: {test_query}\\n\")\n",
    "\n",
    "answer = rag_answer(test_query, k=3)\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922ae3d2",
   "metadata": {},
   "source": [
    "## 4.6 – Evaluation\n",
    "\n",
    "Use the following queries for your evaluation. For each query:\n",
    "\n",
    "- Run `dense_search(query, k=5)` to retrieve relevant documents.\n",
    "- Use `rag_answer(query, k=5)` to generate an answer using the top-5 retrieved documents.\n",
    "\n",
    "**Queries:**\n",
    "1. How do people deal with breakups?\n",
    "2. What do bloggers write about their daily routines?\n",
    "3. How do people feel about their jobs?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d6fb199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not change this code\n",
    "queries = [\n",
    "    \"How do people deal with breakups?\",\n",
    "    \"What do bloggers write about their daily routines?\",\n",
    "    \"How do people feel about their jobs?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53c576f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Q1: How do people deal with breakups?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Top-5 retrieved indices: [5, 3, 1, 0, 11]\n",
      "\n",
      "Top retrieved snippets:\n",
      "[5] Sometimes it's the little things that make life bearable.  Going to a 24 hour post office, mailing priority mail packages.  Go there about 11:30, make a quick stop at Steak N Shake on the way home, an...\n",
      "\n",
      "[3] Tonight I was organizing my friends list on yahoo, deleting people I don't talk to anymore and such. I realized I still have my ex-boyfriend's screen name listed. I very rarely talk to him, but its th...\n",
      "\n",
      "[1] I've been thinking a lot lately. Here I am, on the verge of turning 24 years old, living the life of someone twice that age. I'm tired of each day being routine. I wake up and instead of wondering wha...\n",
      "\n",
      "[0] Recently I was told that I'm obsessive compulsive. I was even compared to the character Monica on the former  Friends  sitcom. At first I didn't agree with that idea. But then I realized how organized...\n",
      "\n",
      "[11] I'm still not making any headway with my family.  In fact, I think Mom has been rallying the troops (aka aunts and uncles) against me.  Meanwhile, my friends have been really supportive of the idea.  ...\n",
      "\n",
      "RAG answer:\n",
      "\n",
      "People are always trying to make sense of the situation, especially when there are no things they can do that would make any sense.  It's like being in a movie where that scene doesn't work out.  There's always something to do but there's nothing to do.\n",
      "\n",
      "[Document 1]: Sometimes you have to take a break to sit around and think about the situation.  Sometimes you have to go out and shop or go to the restaurant or go to the movies or go to a movie in person.  Sometimes you have to go to the bathroom to get out of my life and be with my kids.  Sometimes you have to take the day off and just talk about the situation.  Sometimes you have to talk about your\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Q2: What do bloggers write about their daily routines?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Top-5 retrieved indices: [6, 0, 15, 20, 9]\n",
      "\n",
      "Top retrieved snippets:\n",
      "[6] Ok, so on a couple of websites I shot my mouth off and said, \"I just don't get this blogging thing.\"  Still don't I guess.  First of all I don't understand what all the hubbub is about.  Why are your ...\n",
      "\n",
      "[0] Recently I was told that I'm obsessive compulsive. I was even compared to the character Monica on the former  Friends  sitcom. At first I didn't agree with that idea. But then I realized how organized...\n",
      "\n",
      "[15] It's pretty obvious that I'm not a great learner of lessons, because here I am writing the umpteeth \"first blog entry\" of my life.  Someone, somewhere (probably pretty close to here, actually), is goi...\n",
      "\n",
      "[20] Got a big pack of PC forms in the mail yesterday, including a few for my fingerprints.  With luck, I'll get an interview scheduled this week or next.  How are you doing?  I'm so happy to hear that!  N...\n",
      "\n",
      "[9] Consider the ball rolling.  I've submitted my application and health review, and I've made myself available for assignment starting March 2005....\n",
      "\n",
      "RAG answer:\n",
      "\n",
      "What bloggers write about their daily routine?\n",
      "\n",
      "I'm asking because \"How do bloggers relate to everyday life?\"  If I write about everything I do, that's an interesting question for a blogger to ask.  I may ask how I feel about things like my body, my job, my family, my parents, my hobbies, my hobbies, my family life, my friendships, my family, my work, my family life, my relationships, my health and happiness, my friendships, my sports, my family life, my family life, my family life, my family life, my business, my family life, my family life, my family life, my business, my business life, my business life, my business life, my business\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "Q3: How do people feel about their jobs?\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Top-5 retrieved indices: [14, 20, 8, 5, 18]\n",
      "\n",
      "Top retrieved snippets:\n",
      "[14] I spent a good hour last night paging through the application and making little notes about what to say for the longer, essay portions.  The questions being asked are standard job interview stuff, at ...\n",
      "\n",
      "[20] Got a big pack of PC forms in the mail yesterday, including a few for my fingerprints.  With luck, I'll get an interview scheduled this week or next.  How are you doing?  I'm so happy to hear that!  N...\n",
      "\n",
      "[8] Every day should be a half day.  Took the afternoon off to hit the dentist, and while I was out I managed to get my oil changed, too.  Remember that business with my car dealership this winter?  Well,...\n",
      "\n",
      "[5] Sometimes it's the little things that make life bearable.  Going to a 24 hour post office, mailing priority mail packages.  Go there about 11:30, make a quick stop at Steak N Shake on the way home, an...\n",
      "\n",
      "[18] My parents have the week off work... so when the weekends just aren't enough time to argue about my decisions, now I can do that on Thursday mornings, too!  Something about social circles, I guess: my...\n",
      "\n",
      "RAG answer:\n",
      "\n",
      "That's a good question.  I've been asked this question a lot over the past year, and it's about how I feel about myself, my family, my work, and my family.  It's a question that's been asked since I was a child.  I'm not sure if it was answered with the same kind of attitude that I'm getting today.  What I am sure of is that I am a good person, and that I am a good person.  The question is also about how I feel about all of my colleagues, and all of the people I've worked with.  I know I'm not alone in that.  I got a lot of this from people, and it's a question I'm\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Run and report your evaluation as described above.\n",
    "\n",
    "def run_batch_evaluation(queries, k=5):\n",
    "    for i, query in enumerate(queries, 1):\n",
    "        print(\"=\" * 100)\n",
    "        print(f\"Q{i}: {query}\")\n",
    "        print(\"-\" * 100)\n",
    "\n",
    "        top_k = dense_search(query, k=k)\n",
    "        print(f\"Top-{k} retrieved indices:\", top_k)\n",
    "        print(\"\\nTop retrieved snippets:\")\n",
    "        for idx in top_k:\n",
    "            doc_text = list(docs.values())[idx]['text']\n",
    "            snippet = doc_text.replace(\"\\n\", \" \").strip()\n",
    "            print(f\"[{idx}] {snippet[:200]}...\\n\")\n",
    "\n",
    "        print(\"RAG answer:\\n\")\n",
    "        answer = rag_answer(query, k=k)\n",
    "        print(answer)\n",
    "        print(\"\\n\")\n",
    "\n",
    "# Run the evaluation\n",
    "run_batch_evaluation(queries, k=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
